akka {

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
  }

  loglevel = DEBUG

  persistence {

    journal {

      max-message-batch-size = 200
      max-confirmation-batch-size = 10000
      max-deletion-batch-size = 10000
      plugin = "akka.persistence.journal.leveldb"

      leveldb {
        dir = "target/example/journal"
        native = false
      }
    }

    snapshot-store {
      plugin = "akka.persistence.snapshot-store.local"
    }

    query.journal.leveldb {

      # Implementation class of the LevelDB ReadJournalProvider
      class = "akka.persistence.query.journal.leveldb.LeveldbReadJournalProvider"

      # Absolute path to the write journal plugin configuration entry that this
      # query journal will connect to. That must be a LeveldbJournal or SharedLeveldbJournal.
      # If undefined (or "") it will connect to the default journal as specified by the
      # akka.persistence.journal.plugin property.
      write-plugin = ""

      # The LevelDB write journal is notifying the query side as soon as things
      # are persisted, but for efficiency reasons the query side retrieves the events
      # in batches that sometimes can be delayed up to the configured `refresh-interval`.
      refresh-interval = 3s

      # How many events to fetch in one query (replay) and keep buffered until they
      # are delivered downstreams.
      max-buffer-size = 100

    }

  }

  cluster {
    seed-nodes = [
      "akka.tcp://ClusterSystem@127.0.0.1:2551"]

    auto-down-unreachable-after = 10s
  }

  contrib.cluster.sharding {
    # The extension creates a top level actor with this name in top level user scope,
    # e.g. '/user/sharding'
    guardian-name = sharding
    # If the coordinator can't store state changes it will be stopped
    # and started again after this duration.
    coordinator-failure-backoff = 1 s
    # Start the coordinator singleton manager on members tagged with this role.
    # All members are used if undefined or empty.
    # ShardRegion actor is started in proxy only mode on nodes that are not tagged
    # with this role.
    role = ""
    # The ShardRegion retries registration and shard location requests to the
    # ShardCoordinator with this interval if it does not reply.
    retry-interval = 1 s
    # Maximum number of messages that are buffered by a ShardRegion actor.
    buffer-size = 100000
    # Timeout of the shard rebalancing process.
    handoff-timeout = 60 s
    # Time given to a region to acknowdge it's hosting a shard.
    shard-start-timeout = 10 s
    # If the shard can't store state changes it will retry the action
    # again after this duration. Any messages sent to an affected entry
    # will be buffered until the state change is processed
    shard-failure-backoff = 10 s
    # If the shard is remembering entries and an entry stops itself without
    # using passivate. The entry will be restarted after this duration or when
    # the next message for it is received, which ever occurs first.
    entry-restart-backoff = 10 s
    # Rebalance check is performed periodically with this interval.
    rebalance-interval = 10 s
    # How often the coordinator saves persistent snapshots, which are
    # used to reduce recovery times
    snapshot-interval = 3600 s
    # Setting for the default shard allocation strategy
    least-shard-allocation-strategy {
      # Threshold of how large the difference between most and least number of
      # allocated shards must be to begin the rebalancing.
      rebalance-threshold = 10
      # The number of ongoing rebalancing processes is limited to this number.
      max-simultaneous-rebalance = 3
    }
  }

}
